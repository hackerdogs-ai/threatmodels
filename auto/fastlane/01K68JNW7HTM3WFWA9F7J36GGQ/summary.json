{
  "run_id": "01K68JNW7HTM3WFWA9F7J36GGQ",
  "timestamp": "2025-09-28T09:32:14.956078",
  "execution_time_secs": 0.38,
  "total_cost": 0.0,
  "total_steps": 13,
  "successful_steps": 1,
  "failed_steps": 12,
  "overall_success": false,
  "steps": {
    "architecture_analysis": {
      "success": false,
      "cost": 0.0,
      "total_tokens": 0,
      "input_tokens": 0,
      "output_tokens": 0,
      "execution_time_secs": 0.014792919158935547,
      "error_message": "Failed to use ollama/qwen3:latest ulid:01K68JNW7HTM3WFWA9F7J36GGQ via LiteLLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=qwen3:latest\n Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers"
    },
    "data_flow_diagrams": {
      "success": false,
      "cost": 0.0,
      "total_tokens": 0,
      "input_tokens": 0,
      "output_tokens": 0,
      "execution_time_secs": 0.010832071304321289,
      "error_message": "Failed to use ollama/qwen3:latest ulid:01K68JNW7HTM3WFWA9F7J36GGQ via LiteLLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=qwen3:latest\n Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers"
    },
    "threats": {
      "success": false,
      "cost": 0.0,
      "total_tokens": 0,
      "input_tokens": 0,
      "output_tokens": 0,
      "execution_time_secs": 0.012427806854248047,
      "error_message": "Failed to use ollama/qwen3:latest ulid:01K68JNW7HTM3WFWA9F7J36GGQ via LiteLLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=qwen3:latest\n Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers"
    },
    "attack_trees": {
      "success": false,
      "cost": 0.0,
      "total_tokens": 0,
      "input_tokens": 0,
      "output_tokens": 0,
      "execution_time_secs": 0.01276707649230957,
      "error_message": "Failed to use ollama/qwen3:latest ulid:01K68JNW7HTM3WFWA9F7J36GGQ via LiteLLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=qwen3:latest\n Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers"
    },
    "dread_assessment": {
      "success": false,
      "cost": 0.0,
      "total_tokens": 0,
      "input_tokens": 0,
      "output_tokens": 0,
      "execution_time_secs": 0.01230001449584961,
      "error_message": "Failed to use ollama/qwen3:latest ulid:01K68JNW7HTM3WFWA9F7J36GGQ via LiteLLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=qwen3:latest\n Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers"
    },
    "mitigations": {
      "success": false,
      "cost": 0.0,
      "total_tokens": 0,
      "input_tokens": 0,
      "output_tokens": 0,
      "execution_time_secs": 0.012406110763549805,
      "error_message": "Failed to use ollama/qwen3:latest ulid:01K68JNW7HTM3WFWA9F7J36GGQ via LiteLLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=qwen3:latest\n Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers"
    },
    "test_cases": {
      "success": false,
      "cost": 0.0,
      "total_tokens": 0,
      "input_tokens": 0,
      "output_tokens": 0,
      "execution_time_secs": 0.011919975280761719,
      "error_message": "Failed to use ollama/qwen3:latest ulid:01K68JNW7HTM3WFWA9F7J36GGQ via LiteLLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=qwen3:latest\n Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers"
    },
    "security_controls": {
      "success": false,
      "cost": 0.0,
      "total_tokens": 0,
      "input_tokens": 0,
      "output_tokens": 0,
      "execution_time_secs": 0.011075019836425781,
      "error_message": "Failed to use ollama/qwen3:latest ulid:01K68JNW7HTM3WFWA9F7J36GGQ via LiteLLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=qwen3:latest\n Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers"
    },
    "compliance_assessment": {
      "success": false,
      "cost": 0.0,
      "total_tokens": 0,
      "input_tokens": 0,
      "output_tokens": 0,
      "execution_time_secs": 0.014976739883422852,
      "error_message": "Failed to use ollama/qwen3:latest ulid:01K68JNW7HTM3WFWA9F7J36GGQ via LiteLLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=qwen3:latest\n Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers"
    },
    "risk_prioritization": {
      "success": false,
      "cost": 0.0,
      "total_tokens": 0,
      "input_tokens": 0,
      "output_tokens": 0,
      "execution_time_secs": 0.010780811309814453,
      "error_message": "Failed to use ollama/qwen3:latest ulid:01K68JNW7HTM3WFWA9F7J36GGQ via LiteLLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=qwen3:latest\n Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers"
    },
    "dashboard": {
      "success": true,
      "cost": 0.0,
      "total_tokens": 0,
      "input_tokens": 0,
      "output_tokens": 0,
      "execution_time_secs": 0.0026760101318359375,
      "error_message": null
    },
    "correlations": {
      "success": false,
      "cost": 0.0,
      "total_tokens": 0,
      "input_tokens": 0,
      "output_tokens": 0,
      "execution_time_secs": 0.01093912124633789,
      "error_message": "Failed to use ollama/qwen3:latest ulid:01K68JNW7HTM3WFWA9F7J36GGQ via LiteLLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=qwen3:latest\n Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers"
    },
    "executive_summary": {
      "success": false,
      "cost": 0.0,
      "total_tokens": 0,
      "input_tokens": 0,
      "output_tokens": 0,
      "execution_time_secs": 0.010977029800415039,
      "error_message": "Failed to use ollama/qwen3:latest ulid:01K68JNW7HTM3WFWA9F7J36GGQ via LiteLLM: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=qwen3:latest\n Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers"
    }
  },
  "generated_files": {
    "total_files": 3,
    "files": [
      "12_dashboard_l1_raw.json",
      "12_dashboard_l1_raw.md",
      "12_dashboard_l1_raw.html"
    ],
    "output_directory": "hackerdogs-ai/threatmodels/01K68JNW7HTM3WFWA9F7J36GGQ",
    "ulid": "01K68JNW7HTM3WFWA9F7J36GGQ"
  },
  "output_directory": "hackerdogs-ai/threatmodels/01K68JNW7HTM3WFWA9F7J36GGQ"
}
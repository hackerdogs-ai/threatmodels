Repository: https://github.com/microsoft/autogen

README.md Content:
<a name="readme-top"></a>

<div align="center">
<img src="https://microsoft.github.io/autogen/0.2/img/ag.svg" alt="AutoGen Logo" width="100">

[![Twitter](https://img.shields.io/twitter/url/https/twitter.com/cloudposse.svg?style=social&label=Follow%20%40pyautogen)](https://twitter.com/pyautogen)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-Company?style=flat&logo=linkedin&logoColor=white)](https://www.linkedin.com/company/105812540)
[![Discord](https://img.shields.io/badge/discord-chat-green?logo=discord)](https://aka.ms/autogen-discord)
[![Documentation](https://img.shields.io/badge/Documentation-AutoGen-blue?logo=read-the-docs)](https://microsoft.github.io/autogen/)
[![Blog](https://img.shields.io/badge/Blog-AutoGen-blue?logo=blogger)](https://devblogs.microsoft.com/autogen/)

</div>

# AutoGen

**AutoGen** is a framework for creating multi-agent AI applications that can act autonomously or work alongside humans.

## Installation

AutoGen requires **Python 3.10 or later**.

```bash
# Install AgentChat and OpenAI client from Extensions
pip install -U "autogen-agentchat" "autogen-ext[openai]"
```

The current stable version can be found in the [releases](https://github.com/microsoft/autogen/releases). If you are upgrading from AutoGen v0.2, please refer to the [Migration Guide](https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/migration-guide.html) for detailed instructions on how to update your code and configurations.

```bash
# Install AutoGen Studio for no-code GUI
pip install -U "autogenstudio"
```

## Quickstart

### Hello World

Create an assistant agent using OpenAI's GPT-4o model. See [other supported models](https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/tutorial/models.html).

```python
import asyncio
from autogen_agentchat.agents import AssistantAgent
from autogen_ext.models.openai import OpenAIChatCompletionClient

async def main() -> None:
    model_client = OpenAIChatCompletionClient(model="gpt-4.1")
    agent = AssistantAgent("assistant", model_client=model_client)
    print(await agent.run(task="Say 'Hello World!'"))
    await model_client.close()

asyncio.run(main())
```

### MCP Server

Create a web browsing assistant agent that uses the Playwright MCP server.

```python
# First run `npm install -g @playwright/mcp@latest` to install the MCP server.
import asyncio
from autogen_agentchat.agents import AssistantAgent
from autogen_agentchat.ui import Console
from autogen_ext.models.openai import OpenAIChatCompletionClient
from autogen_ext.tools.mcp import McpWorkbench, StdioServerParams


async def main() -> None:
    model_client = OpenAIChatCompletionClient(model="gpt-4.1")
    server_params = StdioServerParams(
        command="npx",
        args=[
            "@playwright/mcp@latest",
            "--headless",
        ],
    )
    async with McpWorkbench(server_params) as mcp:
        agent = AssistantAgent(
            "web_browsing_assistant",
            model_client=model_client,
            workbench=mcp, # For multiple MCP servers, put them in a list.
            model_client_stream=True,
            max_tool_iterations=10,
        )
        await Console(agent.run_stream(task="Find out how many contributors for the microsoft/autogen repository"))


asyncio.run(main())
```

> **Warning**: Only connect to trusted MCP servers as they may execute commands
> in your local environment or expose sensitive information.

### Multi-Agent Orchestration

You can use `AgentTool` to create a basic multi-agent orchestration setup.

```python
import asyncio

from autogen_agentchat.agents import AssistantAgent
from autogen_agentchat.tools import AgentTool
from autogen_agentchat.ui import Console
from autogen_ext.models.openai import OpenAIChatCompletionClient


async def main() -> None:
    model_client = OpenAIChatCompletionClient(model="gpt-4.1")

    math_agent = AssistantAgent(
        "math_expert",
        model_client=model_client,
        system_message="You are a math expert.",
        description="A math expert assistant.",
        model_client_stream=True,
    )
    math_agent_tool = AgentTool(math_agent, return_value_as_last_message=True)

    chemistry_agent = AssistantAgent(
        "chemistry_expert",
        model_client=model_client,
        system_message="You are a chemistry expert.",
        description="A chemistry expert assistant.",
        model_client_stream=True,
    )
    chemistry_agent_tool = AgentTool(chemistry_agent, return_value_as_last_message=True)

    agent = AssistantAgent(
        "assistant",
        system_message="You are a general assistant. Use expert tools when needed.",
        model_client=model_client,
        model_client_stream=True,
        tools=[math_agent_tool, chemistry_agent_tool],
        max_tool_iterations=10,
    )
    await Console(agent.run_stream(task="What is the integral of x^2?"))
    await Console(agent.run_stream(task="What is the molecular weight of water?"))


asyncio.run(main())
```

For more advanced multi-agent orchestrations and workflows, read
[AgentChat documentation](https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/index.html).

### AutoGen Studio

Use AutoGen Studio to prototype and run multi-agent workflows without writing code.

```bash
# Run AutoGen Studio on http://localhost:8080
autogenstudio ui --port 8080 --appdir ./my-app
```

## Why Use AutoGen?

<div align="center">
  <img src="autogen-landing.jpg" alt="AutoGen Landing" width="500">
</div>

The AutoGen ecosystem provides everything you need to create AI agents, especially multi-agent workflows -- framework, developer tools, and applications.

The _framework_ uses a layered and extensible design. Layers have clearly divided responsibilities and build on top of layers below. This design enables you to use the framework at different levels of abstraction, from high-level APIs to low-level components.

- [Core API](./python/packages/autogen-core/) implements message passing, event-driven agents, and local and distributed runtime for flexibility and power. It also support cross-language support for .NET and Python.
- [AgentChat API](./python/packages/autogen-agentchat/) implements a simpler but opinionatedÂ API for rapid prototyping. This API is built on top of the Core API and is closest to what users of v0.2 are familiar with and supports common multi-agent patterns such as two-agent chat or group chats.
- [Extensions API](./python/packages/autogen-ext/) enables first- and third-party extensions continuously expanding framework capabilities. It support specific implementation of LLM clients (e.g., OpenAI, AzureOpenAI), and capabilities such as code execution.

The ecosystem also supports two essential _developer tools_:

<div align="center">
  <img src="https://media.githubusercontent.com/media/microsoft/autogen/refs/heads/main/python/packages/autogen-studio/docs/ags_screen.png" alt="AutoGen Studio Screenshot" width="500">
</div>

- [AutoGen Studio](./python/packages/autogen-studio/) provides a no-code GUI for building multi-agent applications.
- [AutoGen Bench](./python/packages/agbench/) provides a benchmarking suite for evaluating agent performance.

You can use the AutoGen framework and developer tools to create applications for your domain. For example, [Magentic-One](./python/packages/magentic-one-cli/) is a state-of-the-art multi-agent team built using AgentChat API and Extensions API that can handle a variety of tasks that require web browsing, code execution, and file handling.

With AutoGen you get to join and contribute to a thriving ecosystem. We host weekly office hours and talks with maintainers and community. We also have a [Discord server](https://aka.ms/autogen-discord) for real-time chat, GitHub Discussions for Q&A, and a blog for tutorials and updat...
(README truncated due to length)



JS Files:
File: docs/dotnet/template/public/main.js

File: dotnet/website/template/public/main.js

File: python/docs/src/_static/banner-override.js

File: python/docs/src/_static/custom-icon.js

File: python/docs/src/_static/custom.js
Functions:
function () {
function (event) {
function (element) {
function () {
function () {
function () {
function (element) {
function copyToClipboard(button) {
function createLiveRegion() {
function announceMessage(liveRegion, message) {
... (6 more functions)


PY Files:
File: python/check_md_code_blocks.py
Imports:
import argparse
import logging
import tempfile
from typing import List, Tuple
from pygments import highlight  # type: ignore
... (3 more imports)

File: python/docs/redirects/redirects.py
Imports:
from pathlib import Path
from string import Template
import sys
Functions:
def generate_redirect(file_to_write: str, new_url: str, base_dir: Path):
def main():

File: python/docs/src/_extension/code_lint.py
Imports:
import tempfile
from typing import AbstractSet, Any, Iterable
from docutils import nodes
from sphinx.application import Sphinx
from sphinx.builders import Builder
... (5 more imports)
Classes:
class CodeLinter(Builder):

File: python/docs/src/_extension/gallery_directive.py
Imports:
from pathlib import Path
from typing import Any, ClassVar, Dict, List
from docutils import nodes
from docutils.parsers.rst import directives
from sphinx.application import Sphinx
... (3 more imports)
Classes:
class GalleryGridDirective(SphinxDirective):

File: python/docs/src/conf.py
Imports:
from sphinx.application import Sphinx
from typing import Any, Dict
from pathlib import Path
import sys
import os
... (2 more imports)

File: python/docs/src/generate_api_reference.py
Imports:
import os
from pathlib import Path
from typing import List, Dict, Set
... (1 more imports)
Functions:
def sort_modules_hierarchically(modules):
def main():

File: python/fixup_generated_files.py
Imports:
from pathlib import Path
from typing import Dict
Functions:
def main():

File: python/packages/agbench/benchmarks/GAIA/Scripts/custom_tabulate.py
Imports:
import os
import sys
import re
from agbench.tabulate_cmd import default_tabulate
import json
... (6 more imports)
Functions:
def in_house_normalize_answer(a):
def scorer(instance_dir):
def main(args):

File: python/packages/agbench/benchmarks/GAIA/Scripts/init_tasks.py
Imports:
import json
import os
import re
import sys
from huggingface_hub import snapshot_download
Functions:
def download_gaia():
def create_jsonl(name, tasks, files_dir, template):
def main():

File: python/packages/agbench/benchmarks/GAIA/Templates/MagenticOne/scenario.py
Imports:
import asyncio
import os
import yaml
import warnings
from autogen_ext.agents.magentic_one import MagenticOneCoderAgent
... (10 more imports)

File: python/packages/agbench/benchmarks/GAIA/Templates/ParallelAgents/scenario.py
Imports:
import asyncio
import os
import re
... (28 more imports)
Classes:
class LogHandler(logging.FileHandler):
Functions:
def tee_print(*args, **kwargs):
def team_specific_agentchat_event_logger_info(msg, *args, **kwargs):
def team_specific_core_event_logger_info(msg, *args, **kwargs):
def run_team(team: MagenticOneGroupChat, team_idx: int, task: str, cancellation_token: CancellationToken, logfile):


INFO Files:
Analysis truncated: 1076 more files not analyzed due to token limit.


Repository Analysis Summary:
- Files analyzed: 16 of 1092 total files
- Token usage estimate: ~2829 tokens
- Token limit configured: 4000 tokens
